{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb76c45-2cd1-4dbb-9d9b-fed7c0b80d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "from transformers import * \n",
    "import os\n",
    "from tqdm.auto import tqdm \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler \n",
    "import pickle \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370fd1f1-5053-44f6-a658-7063cda7b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"qa_json(full).json\") as f: \n",
    "    d = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed98c10-3cf2-421e-a6f1-2b87f190709b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7390b760694af2ae9d2a8408a6d3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6786 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queries, passages, answers = [], [], [] \n",
    "\n",
    "for i in tqdm(range(len(d)), position=0, leave=True): \n",
    "    query = d[i][\"query\"] \n",
    "    passage = d[i][\"passages\"]\n",
    "    answer = d[i][\"answer\"] \n",
    "    queries.append(query) \n",
    "    passages.append(passage[0])  \n",
    "    answers.append(answer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66b34b2-2d19-4b6c-a512-a70d92cfc566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.50368405540819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 2545)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(answers)): \n",
    "    if answers[i] in [\"소극\", \"적극\"]: \n",
    "        cnt += 1 \n",
    "        \n",
    "exists = cnt / len(answers) * 100.0 \n",
    "\n",
    "print(exists), cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670ae7a5-ed6d-42d4-aee5-f079f3edd2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>passages</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>설립준비중의 재단법인에 대한 재산의 출연</td>\n",
       "      <td>재단법인의 설립준비중 제3자가 그 설립자에 대하여 장차 설립될 동 법인에 설립을 조...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수임인이 위임사무를 처리함에 있어 받은 물건으로 위임인에게 인도한 목적물은 그것이 ...</td>\n",
       "      <td>집행불능시의 대상청구속에는 예비적으로 이행불능시의 전보배상청구도 포함된 것으로 보고...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>무권대리인의 상대방이 갖는 계약의 이행 또는 손해배상청구권의 소멸시효의 기산점</td>\n",
       "      <td>타인의 대리인으로 계약을 한 자가 그 대리권을 증명하지 못하고 또 본인의 추인을 얻...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>사실혼관계에 있는 당사자의 일방이 모르는 사이에 혼인 신고가 이루어진후 쌍방 당사자...</td>\n",
       "      <td>본법 제139조는 재산법에 관한 총칙규정이고 신분법에 관하여는 그대로 통   용될 ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>남편 소유의 부동산 매각과, 아내의 일상 가사 대리권의 한계</td>\n",
       "      <td>부부간의 일상가사대리권은 그 동거생활을 추지하기 위하여 각각 필요한 범위내의 법률행...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0                             설립준비중의 재단법인에 대한 재산의 출연   \n",
       "1  수임인이 위임사무를 처리함에 있어 받은 물건으로 위임인에게 인도한 목적물은 그것이 ...   \n",
       "2        무권대리인의 상대방이 갖는 계약의 이행 또는 손해배상청구권의 소멸시효의 기산점   \n",
       "3  사실혼관계에 있는 당사자의 일방이 모르는 사이에 혼인 신고가 이루어진후 쌍방 당사자...   \n",
       "4                  남편 소유의 부동산 매각과, 아내의 일상 가사 대리권의 한계   \n",
       "\n",
       "                                            passages answers  \n",
       "0  재단법인의 설립준비중 제3자가 그 설립자에 대하여 장차 설립될 동 법인에 설립을 조...          \n",
       "1  집행불능시의 대상청구속에는 예비적으로 이행불능시의 전보배상청구도 포함된 것으로 보고...          \n",
       "2  타인의 대리인으로 계약을 한 자가 그 대리권을 증명하지 못하고 또 본인의 추인을 얻...          \n",
       "3  본법 제139조는 재산법에 관한 총칙규정이고 신분법에 관하여는 그대로 통   용될 ...          \n",
       "4  부부간의 일상가사대리권은 그 동거생활을 추지하기 위하여 각각 필요한 범위내의 법률행...          "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.DataFrame(list(zip(queries, passages, answers)), columns=[\"queries\", \"passages\", \"answers\"])\n",
    "\n",
    "all_data.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d21f48d-b530-4f10-8d6d-f023fd48bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_index_dict = {} \n",
    "\n",
    "for i in range(len(queries)): \n",
    "    query_index_dict[queries[i]] = [] \n",
    "    \n",
    "for i in range(len(queries)): \n",
    "    query_index_dict[queries[i]].append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99a6729c-40f0-4eec-bf90-18985c99f5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/vocab.txt\n",
      "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/tokenizer_config.json\n",
      "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/vocab.txt\n",
      "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "model_name = \"monologg/kobigbird-bert-base\" \n",
    "q_tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "p_tokenizer = AutoTokenizer.from_pretrained(model_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f49d343e-ff52-4ede-83f8-1d6c14a5c7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5428, 3), (678, 3), (680, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * all_data.shape[0]) \n",
    "val_size = int(0.1 * all_data.shape[0])  \n",
    "\n",
    "train_df = all_data.iloc[:train_size] \n",
    "val_df = all_data.iloc[train_size:train_size+val_size] \n",
    "test_df = all_data.iloc[train_size+val_size:]  \n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07cd7f1-6150-408a-bffb-6a3253d99c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6805bd5477024fd48d6e761a862491eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd62ba90bed4576bf3e96aed8158bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([5428, 512]),\n",
       " torch.Size([5428, 512]),\n",
       " torch.Size([5428, 512]),\n",
       " torch.Size([5428, 512]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions, train_candidates = train_df[\"queries\"].values, train_df[\"passages\"].values \n",
    "\n",
    "q_input_ids, q_attn_masks = [], [] \n",
    "for i in tqdm(range(len(train_questions)), position=0, leave=True): \n",
    "    encoded_inputs = q_tokenizer(str(train_questions[i]), max_length=512, truncation=True, padding=\"max_length\") \n",
    "    q_input_ids.append(encoded_inputs[\"input_ids\"]) \n",
    "    q_attn_masks.append(encoded_inputs[\"attention_mask\"]) \n",
    "\n",
    "c_input_ids, c_attn_masks = [], [] \n",
    "for i in tqdm(range(len(train_candidates)), position=0, leave=True): \n",
    "    encoded_inputs = p_tokenizer(str(train_candidates[i]), max_length=512, truncation=True, padding=\"max_length\") \n",
    "    c_input_ids.append(encoded_inputs[\"input_ids\"]) \n",
    "    c_attn_masks.append(encoded_inputs[\"attention_mask\"]) \n",
    "    \n",
    "q_input_ids = torch.tensor(q_input_ids, dtype=int) \n",
    "q_attn_masks = torch.tensor(q_attn_masks, dtype=int) \n",
    "c_input_ids = torch.tensor(c_input_ids, dtype=int) \n",
    "c_attn_masks = torch.tensor(c_attn_masks, dtype=int) \n",
    "\n",
    "q_input_ids.shape, q_attn_masks.shape, c_input_ids.shape, c_attn_masks.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b1c25a-94e9-4e71-97d2-6bcc4d0fb2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a9b64b693b4a929792b2a680b77a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6786 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([6786, 512]), torch.Size([6786, 512]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare all candidate ids\n",
    "candidates = all_data[\"passages\"].values \n",
    "\n",
    "all_context_input_ids, all_context_attn_masks = [], [] \n",
    "for i in tqdm(range(len(candidates)), position=0, leave=True):\n",
    "    encoded_inputs = p_tokenizer(str(candidates[i]), max_length=512, truncation=True, padding=\"max_length\") \n",
    "    all_context_input_ids.append(encoded_inputs[\"input_ids\"]) \n",
    "    all_context_attn_masks.append(encoded_inputs[\"attention_mask\"]) \n",
    "     \n",
    "all_context_input_ids = torch.tensor(all_context_input_ids, dtype=int) \n",
    "all_context_attn_masks = torch.tensor(all_context_attn_masks, dtype=int)  \n",
    "\n",
    "all_context_input_ids.shape, all_context_attn_masks.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2894f18d-b6dc-4e04-8fe3-b0df5ff63564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"monologg/kobigbird-bert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 3,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32500\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/pytorch_model.bin\n",
      "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BigBirdModel were initialized from the model checkpoint at monologg/kobigbird-bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BigBirdModel for predictions without further training.\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"monologg/kobigbird-bert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 3,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32500\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/pytorch_model.bin\n",
      "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BigBirdModel were initialized from the model checkpoint at monologg/kobigbird-bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BigBirdModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_recall = 0 \n",
    "\n",
    "train_dataset = TensorDataset(q_input_ids, q_attn_masks, c_input_ids, c_attn_masks) \n",
    "train_sampler = RandomSampler(train_dataset) \n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=32) \n",
    "\n",
    "num_train_epochs = 10 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "\n",
    "q_encoder = AutoModel.from_pretrained(\"monologg/kobigbird-bert-base\") \n",
    "q_encoder.to(device) \n",
    "checkpoint = torch.load(\"KoBigBird_query_encoder__.pt\")\n",
    "q_encoder.load_state_dict(checkpoint) \n",
    "\n",
    "p_encoder = AutoModel.from_pretrained(\"monologg/kobigbird-bert-base\") \n",
    "p_encoder.to(device) \n",
    "checkpoint = torch.load(\"KoBigBird_passage_encoder__.pt\")\n",
    "p_encoder.load_state_dict(checkpoint) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ebb7379-52c9-4ccd-ae04-fa470ac77c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = list(q_encoder.parameters()) + list(p_encoder.parameters())  \n",
    "optimizer = AdamW(params, lr=2e-5, eps=1e-8)  \n",
    "t_total = len(train_dataloader) * num_train_epochs \n",
    "q_encoder.zero_grad()  \n",
    "p_encoder.zero_grad()  \n",
    "torch.cuda.empty_cache() \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.05 * t_total), num_training_steps=t_total) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5d91e12-d128-4569-8154-15a6a4f9738c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00512fb7dc3b45169b343586edb41ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99819fd718bc4ada97343bef1e9d43b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 512 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "Attention type 'block_sparse' is not possible if sequence_length: 512 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.7241659341927837\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3bac02c26847f2b81eb9a5c831650c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e2401f3fce462b9a9e9464cca90bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9800884955752213\n",
      "saving best checkpoint so far!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4844aeb0cb41c38ed0bf1c298a7864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.4195954817292445\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2651e0bde8e404ab7cbd115d253f099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b8422fbd8641f6901e13890042ef4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9786135693215339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4084bd28c848429e8ddbd07eb88f6f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.3875195291112451\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57b3ca5c44146569abf0bd13075c6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2b9a5f93c242beb48f0308b6007cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9800884955752213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3b8382a3af491ea48ef60bd5bf0010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.3633478946744136\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb58e4a70b4c4fc4a7e92fc565f8aaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f500396de7e4c4987a02d68c7c60ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9771386430678466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bff495643143da97bdc156b11623e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.3353768384152585\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7d572b20f4442486cc7da07e39b812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc381099e6a84ae48f011e5f594b32f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9771386430678466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3fa9f2beb74da482428f05e29dd780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.31391136891701643\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df9c8d8bbc24470bd6ea9e1bfaa3c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc8d8f29b4e44d6948acfda2d9dfd85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9756637168141593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cc69aaf93f46008916f4c998696c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.28880718599128374\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12eeef0e328d43fdb06fe33162519779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aee6bf5fcd94ee5a1e55daa037dbc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9771386430678466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd97aa482314c1cb4f752ac0a1ad8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.2767469352703569\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cda25d5e9e1490ca02cc255192424a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cbfdf585214c669b02b21943d68d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9786135693215339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a5b29c8f52408b84186c4fbd6d18a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.24528285970651162\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519012e7a00649529cf0a9dd14889390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9006e839fa3d4ee0865c3b1704b00d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9771386430678466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7d497b6f804be5a84aeca697e8eb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss : 0.24846477454240598\n",
      "validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85560a8611d4b14996e7e8d5fc6c7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating candidate embeddings with current model:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape: torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2897bf48684822bc81064bc53ada5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating Recall@50:   0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall@50 : 0.9771386430678466\n",
      "best recall: 0.9800884955752213\n",
      "done training!\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in tqdm(range(0, num_train_epochs), desc=\"Epochs\", position=0, leave=True, total=num_train_epochs): \n",
    "    train_loss = 0\n",
    "    q_encoder.train() \n",
    "    p_encoder.train() \n",
    "    with tqdm(train_dataloader, unit=\"batch\") as tepoch: \n",
    "        for step, batch in enumerate(tepoch): \n",
    "            batch = tuple(t.to(device) for t in batch) \n",
    "            bq_input_ids, bq_attn_masks, bp_input_ids, bp_attn_masks = batch \n",
    "            q_outputs = q_encoder(bq_input_ids, bq_attn_masks).pooler_output \n",
    "            p_outputs = p_encoder(bp_input_ids, bp_attn_masks).pooler_output \n",
    "            # (batch_size * embedding_dims) * (embedding_dims * batch_size) \n",
    "            sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs, 0, 1)) \n",
    "            targets = torch.arange(0, q_outputs.shape[0]).long().to(device) \n",
    "            sim_scores = F.log_softmax(sim_scores, dim=1) \n",
    "            loss = F.nll_loss(sim_scores, targets)  \n",
    "            train_loss += loss.item() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            scheduler.step() \n",
    "            q_encoder.zero_grad() \n",
    "            p_encoder.zero_grad()  \n",
    "            tepoch.set_postfix(loss=train_loss / (step+1))  \n",
    "            time.sleep(0.1) \n",
    "    avg_train_loss = train_loss / len(train_dataloader)  \n",
    "    print(f\"avg train loss : {avg_train_loss}\") \n",
    "    \n",
    "    val_loss = 0\n",
    "    print(\"validating\") \n",
    "    with torch.no_grad(): \n",
    "        p_encoder.eval() \n",
    "        p_embs = [] \n",
    "        inference_dataset = TensorDataset(all_context_input_ids, all_context_attn_masks)\n",
    "        inference_sampler = SequentialSampler(inference_dataset) \n",
    "        inference_dataloader = DataLoader(inference_dataset, sampler=inference_sampler, batch_size=64)\n",
    "        for step, batch in tqdm(enumerate(inference_dataloader), position=0, leave=True, total=len(inference_dataloader), desc=\"calculating candidate embeddings with current model\"):\n",
    "            batch = (t.to(device) for t in batch) \n",
    "            b_input_ids, b_attn_masks = batch \n",
    "            p_emb = p_encoder(b_input_ids, b_attn_masks).pooler_output \n",
    "            for i in range(p_emb.shape[0]): \n",
    "                p_embs.append(torch.reshape(p_emb[i], (-1, 768))) \n",
    "        # p_embs = torch.Tensor(p_embs).squeeze() \n",
    "        p_embs = torch.cat(p_embs, dim=0) \n",
    "        print(f\"candidate embeddings shape: {p_embs.shape}\")  \n",
    "        top_50 = 0 \n",
    "        q_encoder.eval()\n",
    "        val_questions = val_df[\"queries\"].values \n",
    "        for sample_idx in tqdm(range(len(val_questions)), position=0, leave=True, desc=\"calculating Recall@50\"):\n",
    "            query = val_questions[sample_idx] \n",
    "            encoded_query = q_tokenizer(str(query), max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\").to(device) \n",
    "            q_emb = q_encoder(**encoded_query).pooler_output \n",
    "            dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1)) \n",
    "            rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "            correct_idx = query_index_dict[query] # we only have a single correct index in this case  \n",
    "            cnt = 0\n",
    "            for idx in correct_idx: \n",
    "                if idx in rank[:50]: \n",
    "                    cnt += 1 \n",
    "            top_50 += cnt / len(correct_idx) \n",
    "    avg_top50 = top_50 / len(val_questions) \n",
    "    print(f\"mean recall@50 : {avg_top50}\")\n",
    "    if avg_top50 > best_recall: \n",
    "        print(\"saving best checkpoint so far!\") \n",
    "        best_recall = avg_top50 \n",
    "        torch.save(q_encoder.state_dict(), \"large_law_KoBigBird_query_encoder.pt\") \n",
    "        torch.save(p_encoder.state_dict(), \"large_law_KoBigBird_passage_encoder.pt\") \n",
    "\n",
    "print(f\"best recall: {best_recall}\") \n",
    "print(\"done training!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e4bfd1d-f9df-4ba1-bba9-7b96197208c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"monologg/kobigbird-bert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 3,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32500\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/pytorch_model.bin\n",
      "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BigBirdModel were initialized from the model checkpoint at monologg/kobigbird-bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BigBirdModel for predictions without further training.\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/config.json\n",
      "Model config BigBirdConfig {\n",
      "  \"_name_or_path\": \"monologg/kobigbird-bert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BigBirdForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_type\": \"block_sparse\",\n",
      "  \"block_size\": 64,\n",
      "  \"bos_token_id\": 5,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"big_bird\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_random_blocks\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"rescale_embeddings\": false,\n",
      "  \"sep_token_id\": 3,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bias\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32500\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--monologg--kobigbird-bert-base/snapshots/ceacda477e20abef2c929adfa4a07c6f811323be/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BigBirdModel were initialized from the model checkpoint at monologg/kobigbird-bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BigBirdModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "best_q_chkpt = torch.load(\"large_law_KoBigBird_query_encoder.pt\")\n",
    "best_p_chkpt = torch.load(\"large_law_KoBigBird_passage_encoder.pt\")\n",
    "\n",
    "q_encoder = AutoModel.from_pretrained(\"monologg/kobigbird-bert-base\") \n",
    "q_encoder.to(device) \n",
    "print(q_encoder.load_state_dict(best_q_chkpt)) \n",
    "\n",
    "p_encoder = AutoModel.from_pretrained(\"monologg/kobigbird-bert-base\") \n",
    "p_encoder.to(device) \n",
    "print(p_encoder.load_state_dict(best_p_chkpt)) \n",
    "\n",
    "print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881c6d60-03e4-46e5-8675-214194a4522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9257aee54e54aadbf585b2cdbd90c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate embeddings shape : torch.Size([6786, 768])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2907961bc34b1a93eac310b8141df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Recall:   0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL@1:0.7218137254901962 | RECALL@5:0.9161764705882353 | RECALL@10:0.9367647058823529 | RECALL@20:0.9544117647058824 | RECALL@50:0.9691176470588235\n"
     ]
    }
   ],
   "source": [
    "top50_answers = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    p_encoder.eval() \n",
    "    q_encoder.eval() \n",
    "    p_embs = [] \n",
    "\n",
    "    inference_dataset = TensorDataset(all_context_input_ids, all_context_attn_masks) \n",
    "    inference_sampler = SequentialSampler(inference_dataset)\n",
    "    inference_dataloader = DataLoader(inference_dataset, sampler=inference_sampler, batch_size=32) \n",
    "\n",
    "    for step, batch in tqdm(enumerate(inference_dataloader), position=0, leave=True, total=len(inference_dataloader)): \n",
    "        batch = (t.to(device) for t in batch)\n",
    "        b_input_ids, b_attn_masks = batch \n",
    "        p_emb = p_encoder(b_input_ids, b_attn_masks).pooler_output \n",
    "        for i in range(p_emb.shape[0]): \n",
    "            p_embs.append(torch.reshape(p_emb[i], (-1, 768))) \n",
    "\n",
    "    p_embs = torch.cat(p_embs, dim=0)\n",
    "    print(f\"candidate embeddings shape : {p_embs.shape}\") \n",
    "    \n",
    "    top_1, top_5, top_10, top_20, top_50 = 0, 0, 0, 0, 0 \n",
    "    test_questions = test_df[\"queries\"].values \n",
    "    for sample_idx in tqdm(range(len(test_questions)), position=0, leave=True, desc=\"Calculating Recall\"):\n",
    "        query = test_questions[sample_idx] \n",
    "        encoded_query = q_tokenizer(str(query), max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\").to(device) \n",
    "        q_emb = q_encoder(**encoded_query).pooler_output\n",
    "        dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1)) \n",
    "        rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze() \n",
    "        top50_answers.append(rank[:50]) \n",
    "        correct_idx = query_index_dict[query] \n",
    "        \n",
    "        cnt = 0 \n",
    "        for idx in correct_idx: \n",
    "            if idx in rank[:1]: \n",
    "                cnt += 1 \n",
    "        top_1 += cnt / len(correct_idx) \n",
    "        \n",
    "        cnt = 0\n",
    "        for idx in correct_idx: \n",
    "            if idx in rank[:5]: \n",
    "                cnt += 1\n",
    "        top_5 += cnt / len(correct_idx) \n",
    "        \n",
    "        cnt = 0 \n",
    "        for idx in correct_idx: \n",
    "            if idx in rank[:10]:\n",
    "                cnt += 1\n",
    "        top_10 += cnt / len(correct_idx) \n",
    "        \n",
    "        cnt = 0 \n",
    "        for idx in correct_idx:\n",
    "            if idx in rank[:20]:\n",
    "                cnt += 1\n",
    "        top_20 += cnt / len(correct_idx) \n",
    "        \n",
    "        cnt = 0\n",
    "        for idx in correct_idx: \n",
    "            if idx in rank[:50]:\n",
    "                cnt += 1\n",
    "        top_50 += cnt / len(correct_idx) \n",
    "        \n",
    "    avg_top1 = top_1 / len(test_questions) \n",
    "    avg_top5 = top_5 / len(test_questions) \n",
    "    avg_top10 = top_10 / len(test_questions) \n",
    "    avg_top20 = top_20 / len(test_questions) \n",
    "    avg_top50 = top_50 / len(test_questions) \n",
    "    \n",
    "    print(f\"RECALL@1:{avg_top1} | RECALL@5:{avg_top5} | RECALL@10:{avg_top10} | RECALL@20:{avg_top20} | RECALL@50:{avg_top50}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d97b6d-76b0-4357-a9c0-8642099133c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa794fce-d9aa-44a6-91e7-34619e3129d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1bbc1-bbd1-458e-9eea-34bbe0f30552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
